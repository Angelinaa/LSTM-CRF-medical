{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "确认你选择的是搜狗(.scel)词库?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'unichr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7f07993dfffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mdeal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;31m#保存结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7f07993dfffd>\u001b[0m in \u001b[0;36mdeal\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"词库名：\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbyte2str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0x130\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0x338\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.encode('GB18030')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"词库类型：\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbyte2str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0x338\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0x540\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.encode('GB18030')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"描述信息：\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbyte2str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0x540\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0xd40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.encode('GB18030')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7f07993dfffd>\u001b[0m in \u001b[0;36mbyte2str\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munichr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'H'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mu'\\r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mu'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unichr' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python  \n",
    "# -*- coding: utf-8 -*-  \n",
    "  \n",
    "  \n",
    "import struct  \n",
    "import sys  \n",
    "import binascii   \n",
    "import pdb  \n",
    "#搜狗的scel词库就是保存的文本的unicode编码，每两个字节一个字符（中文汉字或者英文字母）  \n",
    "#找出其每部分的偏移位置即可  \n",
    "#主要两部分  \n",
    "#1.全局拼音表，貌似是所有的拼音组合，字典序  \n",
    "#       格式为(index,len,pinyin)的列表  \n",
    "#       index: 两个字节的整数 代表这个拼音的索引  \n",
    "#       len: 两个字节的整数 拼音的字节长度  \n",
    "#       pinyin: 当前的拼音，每个字符两个字节，总长len  \n",
    "#         \n",
    "#2.汉语词组表  \n",
    "#       格式为(same,py_table_len,py_table,{word_len,word,ext_len,ext})的一个列表  \n",
    "#       same: 两个字节 整数 同音词数量  \n",
    "#       py_table_len:  两个字节 整数  \n",
    "#       py_table: 整数列表，每个整数两个字节,每个整数代表一个拼音的索引  \n",
    "#  \n",
    "#       word_len:两个字节 整数 代表中文词组字节数长度  \n",
    "#       word: 中文词组,每个中文汉字两个字节，总长度word_len  \n",
    "#       ext_len: 两个字节 整数 代表扩展信息的长度，好像都是10  \n",
    "#       ext: 扩展信息 前两个字节是一个整数(不知道是不是词频) 后八个字节全是0  \n",
    "#  \n",
    "#      {word_len,word,ext_len,ext} 一共重复same次 同音词 相同拼音表  \n",
    "  \n",
    "#拼音表偏移，  \n",
    "startPy = 0x1540;  \n",
    "  \n",
    "  \n",
    "#汉语词组表偏移  \n",
    "startChinese = 0x2628;  \n",
    "  \n",
    "#全局拼音表  \n",
    "  \n",
    "GPy_Table ={}  \n",
    "  \n",
    "#解析结果  \n",
    "#元组(词频,拼音,中文词组)的列表  \n",
    "GTable = []  \n",
    "  \n",
    "def byte2str(data):  \n",
    "    '''''将原始字节码转为字符串'''  \n",
    "    i = 0;  \n",
    "    length = len(data)  \n",
    "    ret = u''  \n",
    "    while i < length:  \n",
    "        x = data[i] + data[i+1]  \n",
    "        t = unichr(struct.unpack('H',x)[0])  \n",
    "        if t == u'\\r':  \n",
    "            ret += u'\\n'  \n",
    "        elif t != u' ':  \n",
    "            ret += t  \n",
    "        i += 2  \n",
    "    return ret  \n",
    "#获取拼音表  \n",
    "def getPyTable(data):  \n",
    "  \n",
    "    if data[0:4] != \"\\x9D\\x01\\x00\\x00\":  \n",
    "        return None  \n",
    "    data = data[4:]  \n",
    "    pos = 0  \n",
    "    length = len(data)  \n",
    "    while pos < length:  \n",
    "        index = struct.unpack('H',data[pos]+data[pos+1])[0]  \n",
    "        #print index,  \n",
    "        pos += 2  \n",
    "        l = struct.unpack('H',data[pos]+data[pos+1])[0]  \n",
    "        #print l,  \n",
    "        pos += 2  \n",
    "        py = byte2str(data[pos:pos+l])  \n",
    "        #print py  \n",
    "        GPy_Table[index]=py  \n",
    "        pos += l  \n",
    "  \n",
    "#获取一个词组的拼音  \n",
    "def getWordPy(data):  \n",
    "    pos = 0  \n",
    "    length = len(data)  \n",
    "    ret = u''  \n",
    "    while pos < length:  \n",
    "          \n",
    "        index = struct.unpack('H',data[pos]+data[pos+1])[0]  \n",
    "        ret += GPy_Table[index]  \n",
    "        pos += 2      \n",
    "    return ret  \n",
    "  \n",
    "#获取一个词组  \n",
    "def getWord(data):  \n",
    "    pos = 0  \n",
    "    length = len(data)  \n",
    "    ret = u''  \n",
    "    while pos < length:  \n",
    "          \n",
    "        index = struct.unpack('H',data[pos]+data[pos+1])[0]  \n",
    "        ret += GPy_Table[index]  \n",
    "        pos += 2      \n",
    "    return ret  \n",
    "  \n",
    "#读取中文表      \n",
    "def getChinese(data):  \n",
    "    #import pdb  \n",
    "    #pdb.set_trace()  \n",
    "      \n",
    "    pos = 0  \n",
    "    length = len(data)  \n",
    "    while pos < length:  \n",
    "        #同音词数量  \n",
    "        same = struct.unpack('H',data[pos]+data[pos+1])[0]  \n",
    "        #print '[same]:',same,  \n",
    "          \n",
    "        #拼音索引表长度  \n",
    "        pos += 2  \n",
    "        py_table_len = struct.unpack('H',data[pos]+data[pos+1])[0]  \n",
    "        #拼音索引表  \n",
    "        pos += 2  \n",
    "        py = getWordPy(data[pos: pos+py_table_len])  \n",
    "  \n",
    "        #中文词组  \n",
    "        pos += py_table_len  \n",
    "        for i in xrange(same):  \n",
    "            #中文词组长度  \n",
    "            c_len = struct.unpack('H',data[pos]+data[pos+1])[0]  \n",
    "            #中文词组  \n",
    "            pos += 2    \n",
    "            word = byte2str(data[pos: pos + c_len])  \n",
    "            #扩展数据长度  \n",
    "            pos += c_len          \n",
    "            ext_len = struct.unpack('H',data[pos]+data[pos+1])[0]  \n",
    "            #词频  \n",
    "            pos += 2  \n",
    "            count  = struct.unpack('H',data[pos]+data[pos+1])[0]  \n",
    "  \n",
    "            #保存  \n",
    "            GTable.append((count,py,word))  \n",
    "          \n",
    "            #到下个词的偏移位置  \n",
    "            pos +=  ext_len  \n",
    "  \n",
    "  \n",
    "def deal(file_name):  \n",
    "    print( '-'*60)  \n",
    "    f = open(file_name,'rb')  \n",
    "    data = f.read()  \n",
    "    f.close()  \n",
    "      \n",
    "      \n",
    "    if data[0:12] !=\"\\x40\\x15\\x00\\x00\\x44\\x43\\x53\\x01\\x01\\x00\\x00\\x00\":  \n",
    "        print (\"确认你选择的是搜狗(.scel)词库?\"  )\n",
    "        #sys.exit(0)  \n",
    "    #pdb.set_trace()  \n",
    "      \n",
    "    print (\"词库名：\" ,byte2str(data[0x130:0x338]))#.encode('GB18030')  \n",
    "    print (\"词库类型：\" ,byte2str(data[0x338:0x540]))#.encode('GB18030')  \n",
    "    print (\"描述信息：\" ,byte2str(data[0x540:0xd40]))#.encode('GB18030')  \n",
    "    print (\"词库示例：\",byte2str(data[0xd40:startPy]))#.encode('GB18030')  \n",
    "      \n",
    "    getPyTable(data[startPy:startChinese])  \n",
    "    getChinese(data[startChinese:])  \n",
    "      \n",
    "          \n",
    "if __name__ == '__main__':  \n",
    "  \n",
    "    #将要转换的词库添加在这里就可以了  \n",
    "    o = ['words/症状.scel',  \n",
    "    'words/西医病名.scel'\n",
    "    ]  \n",
    "      \n",
    "    for f in o:  \n",
    "        deal(f)  \n",
    "          \n",
    "    #保存结果    \n",
    "    f = open('sougou.txt','w')  \n",
    "    for count,py,word in GTable:  \n",
    "        #GTable保存着结果，是一个列表，每个元素是一个元组(词频,拼音,中文词组)，有需要的话可以保存成自己需要个格式  \n",
    "        #我没排序，所以结果是按照上面输入文件的顺序  \n",
    "        f.write( unicode('{%(count)s}' %{'count':count}+py+' '+ word).encode('GB18030') )#最终保存文件的编码，可以自给改  \n",
    "        f.write('\\n')  \n",
    "    f.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
